{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03339ade-8812-41ff-8e2f-29fa2845afe6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U datasets\n",
    "!pip install -U torch\n",
    "!pip install -U transformers\n",
    "!pip install -U ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aee303b9-11ca-4a70-b01e-4a1b276bf966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding, ElectraForSequenceClassification, AutoTokenizer\n",
    "from datasets import load_dataset, load_metric\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e369ab0c-a0f5-4ae2-b622-16a947069329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer from koelectra-base-v3-discriminator pre-trained model \n",
    "BERT_MODEL = 'monologg/koelectra-base-v3-discriminator'\n",
    "\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e1d1b3-31ae-418e-9463-8ca04d0449ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset from CSV\n",
    "review_dataset_dict = load_dataset('csv', data_files='nsmc_merged.csv', sep=',', names=['document','label'])\n",
    "\n",
    "# dict 에서 train 데이터를 기준으로 dataset 객체 반환\n",
    "review_dataset = review_dataset_dict['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e71c01e-9ff4-4e11-b6da-a4ea0401df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    return bert_tokenizer(data['document'], padding='max_length', truncation=True, max_length=128,pad_to_max_length=True,add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be2a504-8f70-44d7-a0e2-a9784cc7bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_dataset = review_dataset.map(preprocess, batched=True, batch_size=len(review_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbbeaa68-79fd-4a86-ae61-641381ad4196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 클래스 내장 train_test_split 함수를 사용해서 test 데이터 세트를 준비합니다.\n",
    "review_dataset = review_dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544a2d0-4101-4b54-9c7b-f918963d88d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_classification_model = ElectraForSequenceClassification.from_pretrained(\n",
    "    BERT_MODEL, num_labels=2\n",
    ")\n",
    "\n",
    "sequence_classification_model.config.id2label = {0: 'Negative', 1: 'Positive'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d420ce1-1a1f-4d6d-8491-f6cedc8d1d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdb31566-e9bf-45df-94ba-2ec0e487c61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6bd0f9-f3bd-4526-ba72-bbe65766e007",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./clf/results',\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    logging_dir='./clf/logs',\n",
    "    logging_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    evaluation_strategy='epoch',\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "# Define the trainer: \n",
    "\n",
    "trainer = Trainer(\n",
    "    model=sequence_classification_model,\n",
    "    args=training_args,\n",
    "    train_dataset=review_dataset['train'],\n",
    "    eval_dataset=review_dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "173c7d91-9889-424c-807f-0dcb3aea074c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: document. If document are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 39068\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4884' max='2442' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2442/2442 1:07:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.692876398563385,\n",
       " 'eval_accuracy': 0.5126702160335824,\n",
       " 'eval_runtime': 291.4413,\n",
       " 'eval_samples_per_second': 134.051,\n",
       " 'eval_steps_per_second': 8.379}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a258b91f-5a33-49e7-af31-67727376474f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: document. If document are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 156271\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29301\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29301' max='29301' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29301/29301 3:08:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.296500</td>\n",
       "      <td>0.262501</td>\n",
       "      <td>0.902119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.205400</td>\n",
       "      <td>0.277246</td>\n",
       "      <td>0.907034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.136300</td>\n",
       "      <td>0.335169</td>\n",
       "      <td>0.911385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: document. If document are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 39068\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./clf/results/checkpoint-9767\n",
      "Configuration saved in ./clf/results/checkpoint-9767/config.json\n",
      "Model weights saved in ./clf/results/checkpoint-9767/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: document. If document are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 39068\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./clf/results/checkpoint-19534\n",
      "Configuration saved in ./clf/results/checkpoint-19534/config.json\n",
      "Model weights saved in ./clf/results/checkpoint-19534/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: document. If document are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 39068\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./clf/results/checkpoint-29301\n",
      "Configuration saved in ./clf/results/checkpoint-29301/config.json\n",
      "Model weights saved in ./clf/results/checkpoint-29301/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./clf/results/checkpoint-9767 (score: 0.2625013589859009).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=29301, training_loss=0.2127430207826738, metrics={'train_runtime': 11327.7542, 'train_samples_per_second': 41.386, 'train_steps_per_second': 2.587, 'total_flos': 3.083747079912192e+16, 'train_loss': 0.2127430207826738, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c572942-a4d0-4e67-a6b8-e27b45b06438",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: document. If document are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 39068\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2442' max='2442' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2442/2442 04:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2625013589859009,\n",
       " 'eval_accuracy': 0.902119381591072,\n",
       " 'eval_runtime': 294.7628,\n",
       " 'eval_samples_per_second': 132.54,\n",
       " 'eval_steps_per_second': 8.285,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1e465b3-3502-489a-afba-479fbb90c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec28b94-2f4a-4da4-9bea-4d5728d11c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.model\n",
    "tokenizer = bert_tokenizer\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bc71728-6330-4f3e-bf5b-2de5b149afa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'Negative', 'score': 0.5037461519241333},\n",
       " {'label': 'Positive', 'score': 0.4962537884712219}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('이런 영화 정말 오랜만 입니다. 추천해요!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d53e3b37-7d75-4b40-a15a-68c31f9adeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'Negative', 'score': 0.5037662386894226},\n",
       " {'label': 'Positive', 'score': 0.4962337017059326}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('처음에는 좀 망설여지기는 했는데, 그래도 오기를 잘 했다는 생각이 드네여.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b39242c-1f5c-4f7f-9c70-1d65cb21bff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'Negative', 'score': 0.5037504434585571},\n",
       " {'label': 'Positive', 'score': 0.4962495267391205}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('환율이 이렇게 오르면 우리의 수입 물가도 뛸 거라는 거, 또 미국이 금리를 계속 올리고 있는 만큼 환율이 앞으로 더 오를 거라는 겁니다.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92274668-5964-4cd3-80a8-8570bf9a8275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'Negative', 'score': 0.5037599205970764},\n",
       " {'label': 'Positive', 'score': 0.4962400794029236}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('하지만 환자가 점차 나이가 들어가면, 이를 돌보는 가족들은 점점 무기력해진다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7c8c19-a9b6-47f0-a4c4-0e9c2aa00ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
